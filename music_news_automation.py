#!/usr/bin/env python3
"""
Music News Automation System
ìŒì•… ì—…ê³„ ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ - JSON ìƒì„± ê¸°ëŠ¥ í¬í•¨
"""

import sys
import argparse
import logging
from datetime import datetime
from typing import List, Dict

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from advanced_news_collector import AdvancedNewsCollector
from advanced_classifier import AdvancedClassifier
from news_delivery_system import NewsDeliverySystem
from json_generator import MusicNewsJSONGenerator

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('music_news_automation.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class MusicNewsAutomationSystem:
    def __init__(self, test_mode: bool = True):
        self.test_mode = test_mode
        self.collector = AdvancedNewsCollector()
        self.classifier = AdvancedClassifier()
        self.delivery_system = NewsDeliverySystem(test_mode=test_mode)
        self.json_generator = MusicNewsJSONGenerator()
        
        # ì„±ëŠ¥ ì§€í‘œ
        self.start_time = None
        self.metrics = {
            'collection_success_rate': 0,
            'duplicate_removal_count': 0,
            'classification_accuracy': 0,
            'delivery_success_rate': 0,
            'processing_time': 0,
            'total_news_collected': 0,
            'final_news_count': 0
        }
        
        logger.info(f"ìŒì•… ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {test_mode})")
    
    def run_automation(self) -> Dict:
        """ì „ì²´ ìë™í™” í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        self.start_time = datetime.now()
        logger.info("============================================================")
        logger.info("ìŒì•… ì—…ê³„ ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ ì‹œì‘")
        logger.info("============================================================")
        
        try:
            # 1ë‹¨ê³„: RSS í”¼ë“œ ìˆ˜ì§‘
            logger.info("1ë‹¨ê³„: RSS í”¼ë“œ ìˆ˜ì§‘ ì‹œì‘")
            collected_news = self.collector.collect_all_news()
            self.metrics['total_news_collected'] = len(collected_news)
            logger.info(f"1ë‹¨ê³„ ì™„ë£Œ: {len(collected_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘")
            
            if not collected_news:
                logger.warning("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return self._generate_report(success=False)
            
            # 2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ë° íƒœê¹…
            logger.info("2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ë° íƒœê¹… ì‹œì‘")
            processed_news = self.classifier.process_news_list(collected_news)
            logger.info(f"2ë‹¨ê³„ ì™„ë£Œ: {len(processed_news)}ê°œ ë‰´ìŠ¤ ë¶„ë¥˜")
            
            # 3ë‹¨ê³„: ë‰´ìŠ¤ í’ˆì§ˆ ê²€ì¦
            logger.info("3ë‹¨ê³„: ë‰´ìŠ¤ í’ˆì§ˆ ê²€ì¦ ì‹œì‘")
            validated_news = self._validate_news_quality(processed_news)
            logger.info(f"3ë‹¨ê³„ ì™„ë£Œ: {len(validated_news)}ê°œ ë‰´ìŠ¤ ê²€ì¦ í†µê³¼")
            
            # 4ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ë³„ ìƒìœ„ ë‰´ìŠ¤ ì„ ë³„
            logger.info("4ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ë³„ ìƒìœ„ ë‰´ìŠ¤ ì„ ë³„ ì‹œì‘")
            selected_news = self.classifier.select_top_news_by_category(validated_news, max_per_category=4)
            self.metrics['final_news_count'] = len(selected_news)
            logger.info(f"4ë‹¨ê³„ ì™„ë£Œ: {len(selected_news)}ê°œ ë‰´ìŠ¤ ì„ ë³„")
            
            # 5ë‹¨ê³„: ê· í˜•ì„± ë° ë‹¤ì–‘ì„± ê²€ì¦
            logger.info("5ë‹¨ê³„: ê· í˜•ì„± ë° ë‹¤ì–‘ì„± ê²€ì¦ ì‹œì‘")
            final_news = self._verify_balance_and_diversity(selected_news)
            logger.info(f"5ë‹¨ê³„ ì™„ë£Œ: ìµœì¢… {len(final_news)}ê°œ ë‰´ìŠ¤ ì¤€ë¹„")
            
            # 6ë‹¨ê³„: JSON íŒŒì¼ ìƒì„±
            logger.info("6ë‹¨ê³„: JSON íŒŒì¼ ìƒì„± ì‹œì‘")
            json_data = self.json_generator.generate_json_data(final_news)
            json_file = self.json_generator.save_json_file(json_data)
            api_info = self.json_generator.generate_api_info()
            readme_file = self.json_generator.create_readme_for_api()
            logger.info(f"6ë‹¨ê³„ ì™„ë£Œ: JSON íŒŒì¼ ìƒì„± ({json_file})")
            
            # 7ë‹¨ê³„: ë‰´ìŠ¤ ë°œì†¡ (ê¸°ì¡´ Slack/ì´ë©”ì¼)
            logger.info("7ë‹¨ê³„: ë‰´ìŠ¤ ë°œì†¡ ì‹œì‘")
            delivery_result = self.delivery_system.send_news(final_news)
            
            # ë°œì†¡ ì„±ê³µë¥  ê³„ì‚°
            success_count = sum(delivery_result.values())
            total_channels = len(delivery_result)
            success_rate = (success_count / total_channels * 100) if total_channels > 0 else 0
            
            self.metrics['delivery_success_rate'] = success_rate
            logger.info(f"7ë‹¨ê³„ ì™„ë£Œ: ë°œì†¡ ì„±ê³µë¥  {success_rate:.1f}%")
            
            # ì„±ê³µ ë³´ê³ ì„œ ìƒì„±
            return self._generate_report(success=True, final_news=final_news, json_file=json_file)
            
        except Exception as e:
            logger.error(f"ìë™í™” í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return self._generate_report(success=False, error=str(e))
    
    def _validate_news_quality(self, news_list: List[Dict]) -> List[Dict]:
        """ë‰´ìŠ¤ í’ˆì§ˆ ê²€ì¦"""
        validated_news = []
        
        for news in news_list:
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            required_fields = ['title', 'link', 'source']
            if all(news.get(field) for field in required_fields):
                validated_news.append(news)
            else:
                logger.warning(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {news.get('title', 'Unknown')}")
        
        logger.info(f"í’ˆì§ˆ ê²€ì¦: {len(news_list)} -> {len(validated_news)} ê°œ ë‰´ìŠ¤")
        return validated_news
    
    def _verify_balance_and_diversity(self, news_list: List[Dict]) -> List[Dict]:
        """ê· í˜•ì„± ë° ë‹¤ì–‘ì„± ê²€ì¦"""
        # ì¹´í…Œê³ ë¦¬ ë¶„í¬ í™•ì¸
        category_distribution = {}
        for news in news_list:
            category = news.get('category', 'NEWS')
            category_distribution[category] = category_distribution.get(category, 0) + 1
        
        logger.info(f"ì¹´í…Œê³ ë¦¬ ë¶„í¬: {category_distribution}")
        
        # íƒœê·¸ ë‹¤ì–‘ì„± í™•ì¸
        all_genres = set()
        all_industries = set()
        all_regions = set()
        
        for news in news_list:
            tags = news.get('tags', {})
            all_genres.update(tags.get('genre', []))
            all_industries.update(tags.get('industry', []))
            all_regions.update(tags.get('region', []))
        
        diversity_metrics = {
            'genre_diversity': len(all_genres),
            'industry_diversity': len(all_industries),
            'region_diversity': len(all_regions)
        }
        
        logger.info(f"íƒœê·¸ ë‹¤ì–‘ì„±: {diversity_metrics}")
        
        return news_list
    
    def _generate_report(self, success: bool, final_news: List[Dict] = None, 
                        json_file: str = None, error: str = None) -> Dict:
        """ì‹¤í–‰ ë³´ê³ ì„œ ìƒì„±"""
        end_time = datetime.now()
        processing_time = (end_time - self.start_time).total_seconds() if self.start_time else 0
        self.metrics['processing_time'] = processing_time
        
        report = {
            'success': success,
            'timestamp': end_time.isoformat(),
            'processing_time': processing_time,
            'metrics': self.metrics,
            'test_mode': self.test_mode
        }
        
        if success and final_news:
            report.update({
                'final_news_count': len(final_news),
                'json_file': json_file,
                'delivery_success': self.metrics['delivery_success_rate'] > 0
            })
        
        if error:
            report['error'] = error
        
        # ë¡œê·¸ ì¶œë ¥
        logger.info("============================================================")
        logger.info("ìŒì•… ì—…ê³„ ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ")
        logger.info(f"ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ")
        logger.info(f"ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {self.metrics['total_news_collected']}ê°œ")
        logger.info(f"ìµœì¢… ë°œì†¡: {self.metrics['final_news_count']}ê°œ")
        if json_file:
            logger.info(f"JSON íŒŒì¼: {json_file}")
        logger.info(f"ë°œì†¡ ì„±ê³µë¥ : {self.metrics['delivery_success_rate']:.1f}%")
        
        # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
        if processing_time <= 1800:  # 30ë¶„ ì´ë‚´
            logger.info("âœ… ì²˜ë¦¬ ì‹œê°„ ëª©í‘œ ë‹¬ì„± (30ë¶„ ì´ë‚´)")
        else:
            logger.warning("âš ï¸ ì²˜ë¦¬ ì‹œê°„ ëª©í‘œ ë¯¸ë‹¬ì„±")
        
        if self.metrics['delivery_success_rate'] >= 50:  # 50% ì´ìƒ
            logger.info("âœ… ë°œì†¡ ì„±ê³µë¥  ëª©í‘œ ë‹¬ì„±")
        else:
            logger.warning("âš ï¸ ë°œì†¡ ì„±ê³µë¥  ëª©í‘œ ë¯¸ë‹¬ì„±")
        
        logger.info("============================================================")
        
        # ì½˜ì†” ì¶œë ¥ìš© ìš”ì•½
        print("=" * 80)
        print("ğŸµ ìŒì•… ì—…ê³„ ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ ì‹¤í–‰ ë³´ê³ ì„œ")
        print("=" * 80)
        print(f"âœ… ì‹¤í–‰ ìƒíƒœ: {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}")
        print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ")
        print(f"ğŸ“Š ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {self.metrics['total_news_collected']}ê°œ")
        print(f"ğŸ“¤ ìµœì¢… ë°œì†¡: {self.metrics['final_news_count']}ê°œ")
        if json_file:
            print(f"ğŸ“„ JSON íŒŒì¼: {json_file}")
        print(f"ğŸ“± Slack ë°œì†¡: {'ì„±ê³µ' if self.metrics['delivery_success_rate'] > 0 else 'ì‹¤íŒ¨'}")
        print(f"ğŸ“§ ì´ë©”ì¼ ë°œì†¡: {'ì„±ê³µ' if self.metrics['delivery_success_rate'] > 0 else 'ì‹¤íŒ¨'}")
        print(f"ğŸ¯ ë°œì†¡ ì„±ê³µë¥ : {self.metrics['delivery_success_rate']:.1f}%")
        print(f"âœ… ì²˜ë¦¬ ì‹œê°„ ëª©í‘œ ë‹¬ì„± (30ë¶„ ì´ë‚´)" if processing_time <= 1800 else "âš ï¸ ì²˜ë¦¬ ì‹œê°„ ëª©í‘œ ë¯¸ë‹¬ì„±")
        print(f"âœ… ë°œì†¡ ì„±ê³µë¥  ëª©í‘œ ë‹¬ì„±" if self.metrics['delivery_success_rate'] >= 50 else "âš ï¸ ë°œì†¡ ì„±ê³µë¥  ëª©í‘œ ë¯¸ë‹¬ì„±")
        print("=" * 80)
        
        return report

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ìŒì•… ì—…ê³„ ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ')
    parser.add_argument('--production', action='store_true', 
                       help='í”„ë¡œë•ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰ (ì‹¤ì œ ë°œì†¡)')
    parser.add_argument('--json-only', action='store_true',
                       help='JSON íŒŒì¼ë§Œ ìƒì„± (ë°œì†¡ ì—†ìŒ)')
    
    args = parser.parse_args()
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ê²°ì •
    test_mode = not args.production
    
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì‹¤í–‰
        automation_system = MusicNewsAutomationSystem(test_mode=test_mode)
        
        if args.json_only:
            # JSONë§Œ ìƒì„±í•˜ëŠ” ëª¨ë“œ
            logger.info("JSON ì „ìš© ëª¨ë“œë¡œ ì‹¤í–‰")
            collected_news = automation_system.collector.collect_all_news()
            processed_news = automation_system.classifier.process_news_list(collected_news)
            validated_news = automation_system._validate_news_quality(processed_news)
            selected_news = automation_system.classifier.select_top_news_by_category(validated_news)
            
            json_data = automation_system.json_generator.generate_json_data(selected_news)
            json_file = automation_system.json_generator.save_json_file(json_data)
            automation_system.json_generator.generate_api_info()
            automation_system.json_generator.create_readme_for_api()
            
            print(f"JSON íŒŒì¼ ìƒì„± ì™„ë£Œ: {json_file}")
        else:
            # ì „ì²´ ìë™í™” ì‹¤í–‰
            result = automation_system.run_automation()
            
            # ì‹¤í–‰ ê²°ê³¼ì— ë”°ë¥¸ ì¢…ë£Œ ì½”ë“œ ì„¤ì •
            if result['success']:
                sys.exit(0)
            else:
                sys.exit(1)
                
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ í”„ë¡œì„¸ìŠ¤ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()

